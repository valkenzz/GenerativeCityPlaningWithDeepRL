# GenerativeCityPlaningWithDeepRL

The design of cities has a real impact on the happiness of its dwellers. There are many solutions to help make decisions in urban planning, but they barely consider the posterior state. However, no studies were found that explored how a Reinforcement Learning (RL) method can be applied as a recommendation engine for zoning planning. A personalized environment was implemented on Gym with configurable reward functions according to the unique needs of each city. Several experiments were carried out to train RL agents to plan the city. The results showed that policy gradient methods improve slowly but outperform the optimal myopic baseline. Moreover, a qualitative analysis showed that the results are generative and creative. Deep RL methods are relevant for the creation of an urban zoning recommendation engine. Several improvements have not yet been explored, which opens the way to much better results.
Details of studie can be found in presentation.pdf

![image](./Img&Result/GenerativeCity.png)
<br />
*Rl Generated city*

## Repository
The environment is located in city.py, while the Trainings and results are in main.ipynd.
presentation.pdf is the report of this studie.

## Usage
The usage is detailed in the code comments. And the notebook is well explained.

## Contact
For any question or bug, don't hesitate to contact valentin.meo.1@ulaval.ca or theo.cavailles.1@ulaval.ca or use github at : https://github.com/valkenzz/GenerativeCityPlaningWithDeepRL

## Contributing
Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

Please make sure to update tests as appropriate.
## License
[MIT](https://choosealicense.com/licenses/mit/)
